{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeac1bba-4bf5-4495-8d55-4fe47f8677e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizerFast, TFRobertaModel\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8ad99f-5a36-41a2-942d-4b866aefbec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model training notebook: https://github.com/ksv-muralidhar/hugging_face_tf_fine_tuning/blob/main/roberta_text_classification.ipynb\n",
    "tf_model = tf.keras.models.load_model('arxiv_classifier_hf_roberta.h5', custom_objects={\"TFRobertaModel\": TFRobertaModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0b0fb5-c2b5-4deb-97e4-2493393a294f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 200)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobert  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
      " aModel)                     ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 200, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9  (None, 768)                  0         ['tf_roberta_model[0][0]']    \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " dropout_397 (Dropout)       (None, 768)                  0         ['tf.__operators__.getitem_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 768)                  3072      ['dropout_397[0][0]']         \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 512)                  393728    ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_398 (Dropout)       (None, 512)                  0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 512)                  2048      ['dropout_398[0][0]']         \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 256)                  131328    ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_399 (Dropout)       (None, 256)                  0         ['dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 256)                  1024      ['dropout_399[0][0]']         \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 10)                   2570      ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125179402 (477.52 MB)\n",
      "Trainable params: 125176330 (477.51 MB)\n",
      "Non-trainable params: 3072 (12.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e154c08-a3aa-49c2-8c07-fe905cc1d62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125234144"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(os.path.join(\"tflite_models\"))\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"arxiv_classifier_hf_roberta.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53d65b4-81c0-42df-aac9-16f22fed9b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF model size: 1503.006144 MB\n",
      "TFLite model size: 125.234144 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'TF model size: {os.path.getsize(\"arxiv_classifier_hf_roberta.h5\") / 1000000} MB')\n",
    "print(f'TFLite model size: {os.path.getsize(os.path.join(\"tflite_models\", \"arxiv_classifier_hf_roberta.tflite\")) / 1000000} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce8d7a2-1b9d-46f8-ac24-1a11f48dc1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"arxiv_category_preprocessor_labelencoder.bin\", \"rb\") as model_file_obj:\n",
    "        text_preprocessor, label_encoder = cloudpickle.load(model_file_obj)\n",
    "        \n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join(\"tflite_models\", \"arxiv_classifier_hf_roberta.tflite\"))\n",
    "tf_model = tf.keras.models.load_model('arxiv_classifier_hf_roberta.h5', custom_objects={\"TFRobertaModel\": TFRobertaModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f721ae-410c-4940-b7a2-957c47178927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TF model and TFlite model inference\n",
    "\n",
    "def inference(text):\n",
    "    text = text_preprocessor.preprocess(pd.Series(text))[0]\n",
    "    \n",
    "    model_checkpoint = \"roberta-base\"\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(model_checkpoint)\n",
    "    tokens = tokenizer(text, max_length=200, padding=\"max_length\", truncation=True, return_tensors=\"tf\")\n",
    "    \n",
    "    # tflite model inference  \n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    attention_mask, input_ids = tokens['attention_mask'], tokens['input_ids']\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], attention_mask)\n",
    "    interpreter.set_tensor(input_details[1][\"index\"], input_ids)\n",
    "    interpreter.invoke()\n",
    "    tflite_pred = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    tflite_pred_argmax = np.argmax(tflite_pred)\n",
    "    tflite_pred = f\"{label_encoder.inverse_transform([tflite_pred_argmax])} ({tflite_pred[tflite_pred_argmax]})\"\n",
    "    \n",
    "    # tf model inference\n",
    "    input_ = [input_ids, attention_mask]\n",
    "    tf_pred = tf_model.predict(input_, verbose=0)[0]\n",
    "    tf_pred_argmax = np.argmax(tf_pred)\n",
    "    tf_pred = f\"{label_encoder.inverse_transform([tf_pred_argmax])} ({tf_pred[tf_pred_argmax]})\"\n",
    "    print(f'TF Model Prediction: {tf_pred}\\nTFLITE Model Prediction: {tflite_pred}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fc6454-4bd3-4adc-bfbb-952ef6957cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Model Prediction: ['cs'] (0.9761691689491272)\n",
      "TFLITE Model Prediction: ['cs'] (0.9693808555603027)\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. \n",
    "While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on \n",
    "various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. \n",
    "GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in \n",
    "improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing \n",
    "infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict \n",
    "some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.\n",
    "'''\n",
    "_ = inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05e4140-7804-4622-9148-1d3fdb8552d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Model Prediction: ['physics'] (0.9798455834388733)\n",
      "TFLITE Model Prediction: ['physics'] (0.9792115688323975)\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "The Boreal Summer Intraseasonal Oscillation (BSISO) is a pronounced mode of tropical intraseasonal convective \n",
    "variability during the boreal summer. One of the most prominent features of the BSISO is the northward movement\n",
    "of convection in the South Asian monsoon region. Using long-term observational and reanalysis data, we identify\n",
    "two types of BSISO events, one which propagates northward over South Asia from the equatorial Indian Ocean, and\n",
    "the other which doesn't. By investigating the difference between these two types of events, we identify the \n",
    "critical mechanisms involved in northward propagation. A moisture budget reveals that for propagating cases \n",
    "when organized convection first appears over the equatorial Indian Ocean, easterlies on the northern flank of \n",
    "the Rossby wave response to enhanced convection (cyclonic) as well as those on the southern flank of the Rossby \n",
    "wave response (anticyclonic) to the suppressed convection further north act on the climatological moisture distribution, \n",
    "and rapidly moisten the atmosphere over the southern Arabian Sea. This results in the characteristic northwest-southeast-oriented \n",
    "convection observed in the BSISO. Now, as this tilted belt of enhanced convection is present south of the previous cycle \n",
    "of suppressed convection associated with subsidence, in the presence of background easterly vertical shear of the monsoon \n",
    "winds, a latitudinally tilted vortex tilting term is generated due to the meridional gradient in vertical velocity. \n",
    "The generation of positive vorticity anomalies over the Arabian Sea more than over the Bay of Bengal, leads to a \n",
    "tilted gyre north of the convective anomaly.'''\n",
    "_ = inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914ed6b2-9f94-4d8d-a57d-310951f9aab1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Model Prediction: ['physics'] (0.9791610836982727)\n",
      "TFLITE Model Prediction: ['physics'] (0.976417064666748)\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Across the stable density stratification of the abyssal ocean, deep dense water is slowly \n",
    "propelled upward by sustained, though irregular, turbulent mixing. The resulting mean \n",
    "upwelling is key to setting large-scale oceanic circulation properties, such as heat and \n",
    "carbon transport. It is generally accepted that in the ocean interior, this turbulent mixing \n",
    "is caused mainly by breaking internal waves, which are predominantly generated by winds and \n",
    "tides, interact nonlinearly, thereby fluxing energy down to ever smaller scales, and finally \n",
    "become unstable, break and mix the water column. This paradigm forms the conceptual backbone of \n",
    "the widely used Finescale Parameterization. This formula estimates small-scale mixing from the \n",
    "readily observable internal wave activity at larger scales and theoretical scaling laws for the \n",
    "downscale nonlinear energy flux, but has never been fully explained theoretically. Here, we \n",
    "close this gap using wave-wave interaction theory with input from both localized high-resolution \n",
    "experiments and combined global observational datasets. We find near-ubiquitous agreement between \n",
    "our predictions, derived from first-principles alone, and the observed mixing patterns in the global \n",
    "ocean interior. Our findings lay the foundations for a new type of wave-driven mixing parameterization \n",
    "for ocean general circulation models that is entirely physics-based, which is key to reliably \n",
    "represent climate states that differ substantially from today's.\n",
    "'''\n",
    "_ = inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1797e125-72a9-482e-b2fd-a088c30d5f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Model Prediction: ['math'] (0.9992749094963074)\n",
      "TFLITE Model Prediction: ['math'] (0.9992457628250122)\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "We systematically investigate the functors between sites which induce morphisms \n",
    "of relative toposes. In particualar, we establish a relative version of Diaconescu's \n",
    "theorem, characterizing the relative geometric morphisms towards a relative sheaf \n",
    "topos in terms of a notion of flat (equivalently, filtered) functor relative to the base topos.\n",
    "'''\n",
    "_ = inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6c75bf-6b6d-4a3a-844e-cc8052c815c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Model Prediction: ['cs'] (0.5600845813751221)\n",
      "TFLITE Model Prediction: ['cs'] (0.5706031322479248)\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Emotion recognition in conversations (ERC), the task of recognizing the emotion of each \n",
    "utterance in a conversation, is crucial for building empathetic machines. Existing \n",
    "studies focus mainly on capturing context- and speaker-sensitive dependencies on the \n",
    "textual modality but ignore the significance of multimodal information. Different from \n",
    "emotion recognition in textual conversations, capturing intra- and inter-modal interactions \n",
    "between utterances, learning weights between different modalities, and enhancing modal representations \n",
    "play important roles in multimodal ERC. In this paper, we propose a transformer-based model with \n",
    "self-distillation (SDT) for the task. The transformer-based model captures intra- and inter-modal \n",
    "interactions by utilizing intra- and inter-modal transformers, and learns weights between modalities \n",
    "dynamically by designing a hierarchical gated fusion strategy. Furthermore, to learn more expressive \n",
    "modal representations, we treat soft labels of the proposed model as extra training supervision. \n",
    "Specifically, we introduce self-distillation to transfer knowledge of hard and soft labels from \n",
    "the proposed model to each modality. Experiments on IEMOCAP and MELD datasets demonstrate that \n",
    "SDT outperforms previous state-of-the-art baselines.\n",
    "'''\n",
    "_ = inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "552d077c-20b6-4b18-afb1-ea8cadc507bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Model Prediction: ['stat'] (0.7425745129585266)\n",
      "TFLITE Model Prediction: ['stat'] (0.7227165699005127)\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Many enthusiasts and experts publish forecasts of the order players \n",
    "are drafted into professional sports leagues, known as mock drafts. \n",
    "Using a novel dataset of mock drafts for the National Basketball Association (NBA), \n",
    "we analyze authors' mock draft accuracy over time and ask how we can reasonably use \n",
    "information from multiple authors. To measure how accurate mock drafts are, we assume \n",
    "that both mock drafts and the actual draft are ranked lists, and we propose that \n",
    "rank-biased distance (RBD) of Webber et al. (2010) is the appropriate error metric \n",
    "for mock draft accuracy. This is because RBD allows mock drafts to have a different \n",
    "length than the actual draft, accounts for players not appearing in both lists, and \n",
    "weights errors early in the draft more than errors later on. We validate that mock drafts, \n",
    "as expected, improve in accuracy over the course of a season, and that accuracy of the mock \n",
    "drafts produced right before their drafts is fairly stable across seasons. To be able to \n",
    "combine information from multiple mock drafts into a single consensus mock draft, we also \n",
    "propose a ranked-list combination method based on the ideas of ranked-choice voting. \n",
    "We show that our method provides improved forecasts over the standard Borda count combination \n",
    "method used for most similar analyses in sports, and that either combination method provides \n",
    "a more accurate forecast over time than any single author.\n",
    "'''\n",
    "_ = inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82df219-a4bd-4a41-8ecd-587adbfdcb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
