{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TFAutoModelForSeq2SeqLM, ByT5Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:40.907697Z",
     "iopub.status.busy": "2023-07-11T11:00:40.906887Z",
     "iopub.status.idle": "2023-07-11T11:00:40.913846Z",
     "shell.execute_reply": "2023-07-11T11:00:40.912513Z",
     "shell.execute_reply.started": "2023-07-11T11:00:40.907658Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(url: str, n_rows: int):\n",
    "    data = pd.read_csv(url).iloc[:n_rows, 1:]\n",
    "    data = data.sample(frac=1).copy()\n",
    "    data.columns = [\"input\", \"target\"]\n",
    "    data = data.loc[(~data[\"input\"].isna()) & (~data[\"target\"].isna())].copy()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:40.916766Z",
     "iopub.status.busy": "2023-07-11T11:00:40.916106Z",
     "iopub.status.idle": "2023-07-11T11:00:42.708413Z",
     "shell.execute_reply": "2023-07-11T11:00:42.707331Z",
     "shell.execute_reply.started": "2023-07-11T11:00:40.916733Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_data(url=\"data/eng_hindi.csv\", n_rows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:42.711753Z",
     "iopub.status.busy": "2023-07-11T11:00:42.711256Z",
     "iopub.status.idle": "2023-07-11T11:00:42.730323Z",
     "shell.execute_reply": "2023-07-11T11:00:42.728673Z",
     "shell.execute_reply.started": "2023-07-11T11:00:42.711715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>when a bunch of cartoonists in Denmark</td>\n",
       "      <td>जब डेनमार्क के कुछ कार्टूनिस्टों ने</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62641</th>\n",
       "      <td>On sex, reach and Pedersen, adds mobile commun...</td>\n",
       "      <td>लिंग रिच और पेडरसेन पर एड्स.मोबाइल संचार: सामा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>The resultant oil slick led to the death of a ...</td>\n",
       "      <td>इस तेल की बनी मोटी परतों के कारण बहुत सी मछलिय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90314</th>\n",
       "      <td>Among them, the GangaSahastraNam (Hundred name...</td>\n",
       "      <td>जिनमें श्रीगंगासहस्रनामस्तोत्रम् और आरती सबसे ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55049</th>\n",
       "      <td>But he was soon sobered by the innate lucidity...</td>\n",
       "      <td>लेकिन शीर्घ्र ही वे अपने सहज , स्वाभाविक विचार...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  \\\n",
       "3771              when a bunch of cartoonists in Denmark   \n",
       "62641  On sex, reach and Pedersen, adds mobile commun...   \n",
       "1959   The resultant oil slick led to the death of a ...   \n",
       "90314  Among them, the GangaSahastraNam (Hundred name...   \n",
       "55049  But he was soon sobered by the innate lucidity...   \n",
       "\n",
       "                                                  target  \n",
       "3771                 जब डेनमार्क के कुछ कार्टूनिस्टों ने  \n",
       "62641  लिंग रिच और पेडरसेन पर एड्स.मोबाइल संचार: सामा...  \n",
       "1959   इस तेल की बनी मोटी परतों के कारण बहुत सी मछलिय...  \n",
       "90314  जिनमें श्रीगंगासहस्रनामस्तोत्रम् और आरती सबसे ...  \n",
       "55049  लेकिन शीर्घ्र ही वे अपने सहज , स्वाभाविक विचार...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:42.732976Z",
     "iopub.status.busy": "2023-07-11T11:00:42.731830Z",
     "iopub.status.idle": "2023-07-11T11:00:42.740918Z",
     "shell.execute_reply": "2023-07-11T11:00:42.740014Z",
     "shell.execute_reply.started": "2023-07-11T11:00:42.732940Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame):\n",
    "    data = data.copy()\n",
    "    data[\"input\"] = data[\"input\"].map(unidecode).copy()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:42.742875Z",
     "iopub.status.busy": "2023-07-11T11:00:42.742415Z",
     "iopub.status.idle": "2023-07-11T11:00:43.273473Z",
     "shell.execute_reply": "2023-07-11T11:00:43.272312Z",
     "shell.execute_reply.started": "2023-07-11T11:00:42.742840Z"
    }
   },
   "outputs": [],
   "source": [
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:43.275388Z",
     "iopub.status.busy": "2023-07-11T11:00:43.274976Z",
     "iopub.status.idle": "2023-07-11T11:00:43.289550Z",
     "shell.execute_reply": "2023-07-11T11:00:43.288373Z",
     "shell.execute_reply.started": "2023-07-11T11:00:43.275352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>when a bunch of cartoonists in Denmark.</td>\n",
       "      <td>जब डेनमार्क के कुछ कार्टूनिस्टों ने.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62641</th>\n",
       "      <td>On sex, reach and Pedersen, adds mobile commun...</td>\n",
       "      <td>लिंग रिच और पेडरसेन पर एड्स.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>The resultant oil slick led to the death of a ...</td>\n",
       "      <td>इस तेल की बनी मोटी परतों के कारण बहुत सी मछलिय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90314</th>\n",
       "      <td>Among them, the GangaSahastraNam (Hundred name...</td>\n",
       "      <td>जिनमें श्रीगंगासहस्रनामस्तोत्रम् और आरती सबसे ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55049</th>\n",
       "      <td>But he was soon sobered by the innate lucidity...</td>\n",
       "      <td>लेकिन शीर्घ्र ही वे अपने सहज , स्वाभाविक विचार...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81648</th>\n",
       "      <td>Apart from him, several other Litterateurs hav...</td>\n",
       "      <td>इनके अलावा और भी अनेक साहित्यकारों ने रामायण स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92496</th>\n",
       "      <td>And this is very similar to a Q and U example.</td>\n",
       "      <td>और यह बहुत कुछ एक Q और U के उदाहरण जैसा है।.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16893</th>\n",
       "      <td>No wonder hybrid corn has revolutionised agric...</td>\n",
       "      <td>इस बात पर कोई आश्चर्य नहीं होना चाहिए कि अमेरि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92093</th>\n",
       "      <td>Do n't be worried that babies might be sick an...</td>\n",
       "      <td>इस बात की चिन्ता न करें कि यदि शिशुओं को पीठ प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77878</th>\n",
       "      <td>They localized it into 18 different languages.</td>\n",
       "      <td>उन्होनें इसे १८ स्थानीय भाषाओँ में रूपांतरित क...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  \\\n",
       "3771             when a bunch of cartoonists in Denmark.   \n",
       "62641  On sex, reach and Pedersen, adds mobile commun...   \n",
       "1959   The resultant oil slick led to the death of a ...   \n",
       "90314  Among them, the GangaSahastraNam (Hundred name...   \n",
       "55049  But he was soon sobered by the innate lucidity...   \n",
       "...                                                  ...   \n",
       "81648  Apart from him, several other Litterateurs hav...   \n",
       "92496     And this is very similar to a Q and U example.   \n",
       "16893  No wonder hybrid corn has revolutionised agric...   \n",
       "92093  Do n't be worried that babies might be sick an...   \n",
       "77878     They localized it into 18 different languages.   \n",
       "\n",
       "                                                  target  \n",
       "3771                जब डेनमार्क के कुछ कार्टूनिस्टों ने.  \n",
       "62641                       लिंग रिच और पेडरसेन पर एड्स.  \n",
       "1959   इस तेल की बनी मोटी परतों के कारण बहुत सी मछलिय...  \n",
       "90314  जिनमें श्रीगंगासहस्रनामस्तोत्रम् और आरती सबसे ...  \n",
       "55049  लेकिन शीर्घ्र ही वे अपने सहज , स्वाभाविक विचार...  \n",
       "...                                                  ...  \n",
       "81648  इनके अलावा और भी अनेक साहित्यकारों ने रामायण स...  \n",
       "92496       और यह बहुत कुछ एक Q और U के उदाहरण जैसा है।.  \n",
       "16893  इस बात पर कोई आश्चर्य नहीं होना चाहिए कि अमेरि...  \n",
       "92093  इस बात की चिन्ता न करें कि यदि शिशुओं को पीठ प...  \n",
       "77878  उन्होनें इसे १८ स्थानीय भाषाओँ में रूपांतरित क...  \n",
       "\n",
       "[99998 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:43.292658Z",
     "iopub.status.busy": "2023-07-11T11:00:43.291432Z",
     "iopub.status.idle": "2023-07-11T11:00:43.304939Z",
     "shell.execute_reply": "2023-07-11T11:00:43.303450Z",
     "shell.execute_reply.started": "2023-07-11T11:00:43.292600Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame, input_col: str=\"input\", target_col: str=\"target\", test_size: float=0.1):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data[input_col], data[target_col], \n",
    "                                                        random_state=42, test_size=test_size)\n",
    "    \n",
    "    print(f'x_train.shape: {x_train.shape}, x_test.shape: {x_test.shape}, '+\n",
    "          f'y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}')\n",
    "    x_train, x_test, y_train, y_test = x_train.to_list(), x_test.to_list(), y_train.to_list(), y_test.to_list()\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:43.308504Z",
     "iopub.status.busy": "2023-07-11T11:00:43.308025Z",
     "iopub.status.idle": "2023-07-11T11:00:43.346693Z",
     "shell.execute_reply": "2023-07-11T11:00:43.345432Z",
     "shell.execute_reply.started": "2023-07-11T11:00:43.308462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (89998,), x_test.shape: (10000,), y_train.shape: (89998,), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:43.351697Z",
     "iopub.status.busy": "2023-07-11T11:00:43.351363Z",
     "iopub.status.idle": "2023-07-11T11:00:43.359109Z",
     "shell.execute_reply": "2023-07-11T11:00:43.357796Z",
     "shell.execute_reply.started": "2023-07-11T11:00:43.351670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The component of probable present radiative forcing by IPCC Fourth Assessment Report.',\n",
       " 'आईपीसीसी की चतुर्थ मूल्यांकन रिर्पोट द्वारा (radiative forcing)अनुमानित वर्तमान विकिरणशील बाध्यता के घटक (IPCC Fourth Assessment Report).')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:43.361677Z",
     "iopub.status.busy": "2023-07-11T11:00:43.361234Z",
     "iopub.status.idle": "2023-07-11T11:00:49.454519Z",
     "shell.execute_reply": "2023-07-11T11:00:49.453400Z",
     "shell.execute_reply.started": "2023-07-11T11:00:43.361608Z"
    }
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "CHECKPOINT = \"google/byt5-small\"\n",
    "N_TOKENS = 200\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:49.456895Z",
     "iopub.status.busy": "2023-07-11T11:00:49.456469Z",
     "iopub.status.idle": "2023-07-11T11:00:49.464277Z",
     "shell.execute_reply": "2023-07-11T11:00:49.462240Z",
     "shell.execute_reply.started": "2023-07-11T11:00:49.456859Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(input: list, target: list, n_tokens: int):\n",
    "    tokenizer = ByT5Tokenizer.from_pretrained(CHECKPOINT)\n",
    "    print(f'Example:\\n{input[0]}\\n{tokenizer.tokenize(input[0])}')\n",
    "    tokenized_data = tokenizer(text=input, text_target=target, \n",
    "                               max_length=n_tokens, truncation=True, padding=\"max_length\")\n",
    "    return tokenized_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:49.467063Z",
     "iopub.status.busy": "2023-07-11T11:00:49.466606Z",
     "iopub.status.idle": "2023-07-11T11:00:50.002958Z",
     "shell.execute_reply": "2023-07-11T11:00:50.002045Z",
     "shell.execute_reply.started": "2023-07-11T11:00:49.467029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc3eba410dc40358c8787dc3bb21bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa13099cd82b4b2495f83991a9f89f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4ccfe33bf4436e9679bc37855f6276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "She walked out of the plane.\n",
      "['S', 'h', 'e', ' ', 'w', 'a', 'l', 'k', 'e', 'd', ' ', 'o', 'u', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'l', 'a', 'n', 'e', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[86, 107, 104, 35, 122, 100, 111, 110, 104, 103, 35, 114, 120, 119, 35, 114, 105, 35, 119, 107, 104, 35, 115, 111, 100, 113, 104, 49, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [76, 35, 102, 100, 113, 35, 100, 111, 118, 114, 35, 103, 114, 35, 118, 114, 112, 104, 35, 77, 100, 102, 110, 108, 104, 35, 70, 107, 100, 113, 48, 112, 114, 119, 108, 114, 113, 47, 49, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[227, 167, 184, 227, 168, 142, 35, 227, 167, 188, 227, 167, 184, 227, 167, 193, 227, 167, 139, 48, 227, 167, 159, 227, 167, 188, 227, 167, 193, 227, 167, 159, 35, 227, 167, 187, 227, 168, 138, 35, 227, 167, 175, 227, 167, 193, 227, 167, 188, 227, 167, 179, 35, 227, 167, 171, 227, 167, 194, 227, 167, 152, 227, 167, 181, 227, 168, 131, 35, 227, 167, 151, 227, 167, 179, 49, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [227, 167, 177, 227, 168, 139, 227, 167, 133, 35, 227, 167, 159, 227, 168, 139, 227, 167, 152, 227, 168, 131, 35, 227, 167, 157, 227, 168, 138, 227, 167, 171, 35, 227, 167, 152, 227, 168, 131, 35, 227, 167, 167, 227, 167, 179, 227, 167, 188, 35, 227, 167, 178, 227, 168, 132, 227, 167, 169, 227, 168, 144, 227, 167, 170, 35, 227, 167, 152, 227, 167, 181, 227, 167, 193, 35, 227, 167, 152, 227, 168, 131, 35, 227, 167, 152, 227, 167, 181, 227, 167, 193, 227, 167, 175, 227, 167, 193, 227, 167, 159, 227, 167, 191, 227, 168, 131, 49, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(input=x_train[-2:], target=y_train[-2:], n_tokens=N_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:00:50.005109Z",
     "iopub.status.busy": "2023-07-11T11:00:50.004448Z",
     "iopub.status.idle": "2023-07-11T11:01:54.960749Z",
     "shell.execute_reply": "2023-07-11T11:01:54.959701Z",
     "shell.execute_reply.started": "2023-07-11T11:00:50.005055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "The component of probable present radiative forcing by IPCC Fourth Assessment Report.\n",
      "['T', 'h', 'e', ' ', 'c', 'o', 'm', 'p', 'o', 'n', 'e', 'n', 't', ' ', 'o', 'f', ' ', 'p', 'r', 'o', 'b', 'a', 'b', 'l', 'e', ' ', 'p', 'r', 'e', 's', 'e', 'n', 't', ' ', 'r', 'a', 'd', 'i', 'a', 't', 'i', 'v', 'e', ' ', 'f', 'o', 'r', 'c', 'i', 'n', 'g', ' ', 'b', 'y', ' ', 'I', 'P', 'C', 'C', ' ', 'F', 'o', 'u', 'r', 't', 'h', ' ', 'A', 's', 's', 'e', 's', 's', 'm', 'e', 'n', 't', ' ', 'R', 'e', 'p', 'o', 'r', 't', '.']\n",
      "Example:\n",
      "The namaskara-mandapa has profuse wood-carvings , while the wall of the shrine has interesting mural paintings .\n",
      "['T', 'h', 'e', ' ', 'n', 'a', 'm', 'a', 's', 'k', 'a', 'r', 'a', '-', 'm', 'a', 'n', 'd', 'a', 'p', 'a', ' ', 'h', 'a', 's', ' ', 'p', 'r', 'o', 'f', 'u', 's', 'e', ' ', 'w', 'o', 'o', 'd', '-', 'c', 'a', 'r', 'v', 'i', 'n', 'g', 's', ' ', ',', ' ', 'w', 'h', 'i', 'l', 'e', ' ', 't', 'h', 'e', ' ', 'w', 'a', 'l', 'l', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 's', 'h', 'r', 'i', 'n', 'e', ' ', 'h', 'a', 's', ' ', 'i', 'n', 't', 'e', 'r', 'e', 's', 't', 'i', 'n', 'g', ' ', 'm', 'u', 'r', 'a', 'l', ' ', 'p', 'a', 'i', 'n', 't', 'i', 'n', 'g', 's', ' ', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = tokenize(input=x_train, target=y_train, n_tokens=N_TOKENS)\n",
    "tokenized_test = tokenize(input=x_test, target=y_test, n_tokens=N_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:01:54.965328Z",
     "iopub.status.busy": "2023-07-11T11:01:54.965034Z",
     "iopub.status.idle": "2023-07-11T11:01:54.970040Z",
     "shell.execute_reply": "2023-07-11T11:01:54.968990Z",
     "shell.execute_reply.started": "2023-07-11T11:01:54.965303Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_tf_tensors(data):\n",
    "    data = tf.data.Dataset.from_tensor_slices(dict(data))\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:01:54.972308Z",
     "iopub.status.busy": "2023-07-11T11:01:54.971701Z",
     "iopub.status.idle": "2023-07-11T11:04:54.700014Z",
     "shell.execute_reply": "2023-07-11T11:04:54.699013Z",
     "shell.execute_reply.started": "2023-07-11T11:01:54.972273Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tf_data = return_tf_tensors(tokenized_train)\n",
    "test_tf_data = return_tf_tensors(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:04:54.702423Z",
     "iopub.status.busy": "2023-07-11T11:04:54.701361Z",
     "iopub.status.idle": "2023-07-11T11:04:54.971455Z",
     "shell.execute_reply": "2023-07-11T11:04:54.970212Z",
     "shell.execute_reply.started": "2023-07-11T11:04:54.702385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([ 87, 107, 104,  35, 102, 114, 112, 115, 114, 113, 104, 113, 119,\n",
      "        35, 114, 105,  35, 115, 117, 114, 101, 100, 101, 111, 104,  35,\n",
      "       115, 117, 104, 118, 104, 113, 119,  35, 117, 100, 103, 108, 100,\n",
      "       119, 108, 121, 104,  35, 105, 114, 117, 102, 108, 113, 106,  35,\n",
      "       101, 124,  35,  76,  83,  70,  70,  35,  73, 114, 120, 117, 119,\n",
      "       107,  35,  68, 118, 118, 104, 118, 118, 112, 104, 113, 119,  35,\n",
      "        85, 104, 115, 114, 117, 119,  49,   1,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0], dtype=int32)>, 'labels': <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([227, 167, 137, 227, 167, 139, 227, 167, 173, 227, 168, 131, 227,\n",
      "       167, 187, 227, 168, 131, 227, 167, 187, 227, 168, 131,  35, 227,\n",
      "       167, 152, 227, 168, 131,  35, 227, 167, 157, 227, 167, 167, 227,\n",
      "       168, 132, 227, 167, 179, 227, 168, 144, 227, 167, 168,  35, 227,\n",
      "       167, 177, 227, 168, 133, 227, 167, 181, 227, 168, 144, 227, 167,\n",
      "       178, 227, 167, 193, 227, 167, 133, 227, 167, 152, 227, 167, 171,\n",
      "        35, 227, 167, 179, 227, 167, 194, 227, 167, 179, 227, 168, 144,\n",
      "       227, 167, 173, 227, 168, 142, 227, 167, 162,  35, 227, 167, 169,\n",
      "       227, 168, 144, 227, 167, 184, 227, 167, 193, 227, 167, 179, 227,\n",
      "       167, 193,  35,  43, 117, 100, 103, 108, 100, 119, 108, 121, 104,\n",
      "        35, 105, 114, 117, 102, 108, 113, 106,  44, 227, 167, 136, 227,\n",
      "       167, 171, 227, 168, 132, 227, 167, 177, 227, 167, 193, 227, 167,\n",
      "       171, 227, 167, 194, 227, 167, 167,  35, 227, 167, 184, 227, 167,\n",
      "       179, 227, 168, 144, 227, 167, 167, 227, 167, 177, 227, 167, 193,\n",
      "       227, 167, 171,  35, 227, 167, 184, 227, 167, 194, 227, 167, 152,\n",
      "       227, 167, 194, 227,   1], dtype=int32)>}\n",
      "{'input_ids': <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([ 69, 104, 105, 114, 117, 104,  35, 124, 114, 120,  35, 105, 108,\n",
      "       111, 111,  35, 108, 113,  35, 124, 114, 120, 117,  35, 105, 114,\n",
      "       117, 112,  35,  47,  35, 102, 107, 104, 102, 110,  35, 119, 107,\n",
      "       100, 119,  35, 124, 114, 120,  35, 100, 117, 104,  35, 100, 115,\n",
      "       115, 111, 124, 108, 113, 106,  35, 105, 114, 117,  35, 104, 121,\n",
      "       104, 117, 124, 119, 107, 108, 113, 106,  35, 124, 114, 120,  35,\n",
      "       112, 100, 124,  35, 101, 104,  35, 104, 113, 119, 108, 119, 111,\n",
      "       104, 103,  35, 119, 114,  35,  49,   1,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0], dtype=int32)>, 'labels': <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([227, 167, 137, 227, 167, 173,  35, 227, 167, 174, 227, 168, 140,\n",
      "       227, 167, 179, 227, 168, 144, 227, 167, 177,  35, 227, 167, 176,\n",
      "       227, 167, 179, 227, 167, 171, 227, 168, 138,  35, 227, 167, 187,\n",
      "       227, 168, 138,  35, 227, 167, 173, 227, 167, 188, 227, 167, 181,\n",
      "       227, 168, 138,  35,  47,  35, 227, 167, 152, 227, 168, 134, 227,\n",
      "       167, 173, 227, 167, 178, 227, 167, 193,  35, 227, 167, 178, 227,\n",
      "       167, 188,  35, 227, 167, 173, 227, 167, 167, 227, 167, 193,  35,\n",
      "       227, 167, 152, 227, 167, 179,  35, 227, 167, 152, 227, 168, 138,\n",
      "        35, 227, 167, 171, 227, 167, 194, 227, 167, 185, 227, 168, 144,\n",
      "       227, 167, 157, 227, 167, 194, 227, 167, 167,  35, 227, 167, 152,\n",
      "       227, 167, 179,  35, 227, 167, 181, 227, 168, 138,  35, 227, 167,\n",
      "       152, 227, 167, 194,  35, 227, 167, 137, 227, 167, 173,  35, 227,\n",
      "       167, 140, 227, 167, 187,  35, 227, 167, 187, 227, 167, 193, 227,\n",
      "       167, 179, 227, 168, 131,  35, 227, 167, 157, 227, 168, 131, 227,\n",
      "       167, 159, 227, 168, 142, 227, 167, 133,  35, 227, 167, 152, 227,\n",
      "       168, 138,  35, 227,   1], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "for i in train_tf_data.take(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:04:54.977436Z",
     "iopub.status.busy": "2023-07-11T11:04:54.975579Z",
     "iopub.status.idle": "2023-07-11T11:04:54.985420Z",
     "shell.execute_reply": "2023-07-11T11:04:54.984303Z",
     "shell.execute_reply.started": "2023-07-11T11:04:54.977398Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(train_data, val_data, epochs=2, eta=1e-4, early_stopping_patience=1, batch_size=BATCH_SIZE):\n",
    "    with strategy.scope():\n",
    "        model = TFAutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(eta))\n",
    "\n",
    "    print(model.summary())\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=early_stopping_patience, mode=\"min\")\n",
    "    model.fit(train_data.shuffle(len(train_data)).batch(batch_size), validation_data=val_data.shuffle(len(val_data)).batch(batch_size), \n",
    "          epochs=epochs, callbacks=[early_stop])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T11:04:54.989151Z",
     "iopub.status.busy": "2023-07-11T11:04:54.988853Z",
     "iopub.status.idle": "2023-07-11T15:18:58.791333Z",
     "shell.execute_reply": "2023-07-11T15:18:58.790403Z",
     "shell.execute_reply.started": "2023-07-11T11:04:54.989115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924311b5f6e54eaaa52f46995cbd3bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at google/byt5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e338a04a3441bcb546b6cdcf407fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tft5_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shared (Embedding)          multiple                  565248    \n",
      "                                                                 \n",
      " encoder (TFT5MainLayer)     multiple                  217657472 \n",
      "                                                                 \n",
      " decoder (TFT5MainLayer)     multiple                  81980288  \n",
      "                                                                 \n",
      " lm_head (Dense)             multiple                  565248    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,637,760\n",
      "Trainable params: 299,637,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "5625/5625 [==============================] - 7677s 1s/step - loss: 0.7390 - val_loss: 0.3465\n",
      "Epoch 2/2\n",
      "5625/5625 [==============================] - 7541s 1s/step - loss: 0.3587 - val_loss: 0.2830\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(train_data=train_tf_data, val_data=test_tf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T15:23:32.813755Z",
     "iopub.status.busy": "2023-07-11T15:23:32.813360Z",
     "iopub.status.idle": "2023-07-11T15:23:32.825752Z",
     "shell.execute_reply": "2023-07-11T15:23:32.824684Z",
     "shell.execute_reply.started": "2023-07-11T15:23:32.813724Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_tokenize(input: list, n_tokens: int):\n",
    "    tokenizer = ByT5Tokenizer.from_pretrained(CHECKPOINT)\n",
    "    tokenized_data = tokenizer(text=input, max_length=n_tokens, truncation=True, padding=\"max_length\", return_tensors=\"tf\")\n",
    "    return tokenizer, tokenized_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T15:25:21.208724Z",
     "iopub.status.busy": "2023-07-11T15:25:21.208350Z",
     "iopub.status.idle": "2023-07-11T15:25:21.215418Z",
     "shell.execute_reply": "2023-07-11T15:25:21.214214Z",
     "shell.execute_reply.started": "2023-07-11T15:25:21.208693Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(txt: str):\n",
    "    test_data = [txt]\n",
    "    inference_tokenizer, tokenized_data = inference_tokenize(input=test_data, n_tokens=N_TOKENS)\n",
    "    pred = model.generate(**tokenized_data, max_new_tokens=N_TOKENS)\n",
    "    result = inference_tokenizer.decode(pred[0])\n",
    "    result = re.sub(\"<.*?>\", \"\", result)\n",
    "    print(f\"ENGLISH:\\n{txt}\\n\\nHINDI:\\n{result}\")\n",
    "    return (txt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T15:34:10.888567Z",
     "iopub.status.busy": "2023-07-11T15:34:10.888214Z",
     "iopub.status.idle": "2023-07-11T15:34:15.803315Z",
     "shell.execute_reply": "2023-07-11T15:34:15.802338Z",
     "shell.execute_reply.started": "2023-07-11T15:34:10.888536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH:\n",
      "What is your name?\n",
      "\n",
      "HINDI:\n",
      "आपका नाम क्या है?.\n"
     ]
    }
   ],
   "source": [
    "txt = \"What is your name?\"\n",
    "txt, result = inference(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T15:50:47.012772Z",
     "iopub.status.busy": "2023-07-11T15:50:47.012335Z",
     "iopub.status.idle": "2023-07-11T15:51:01.758890Z",
     "shell.execute_reply": "2023-07-11T15:51:01.757807Z",
     "shell.execute_reply.started": "2023-07-11T15:50:47.012737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH:\n",
      "The imports of grey goods from Japan increased from 75.\n",
      "\n",
      "HINDI:\n",
      "जापान से काफी उपभोक्ताओं की कमी से बढ़ती गई थी।.\n"
     ]
    }
   ],
   "source": [
    "txt = x_test[1]\n",
    "txt, result = inference(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T15:51:36.495698Z",
     "iopub.status.busy": "2023-07-11T15:51:36.495307Z",
     "iopub.status.idle": "2023-07-11T15:51:42.380955Z",
     "shell.execute_reply": "2023-07-11T15:51:42.379028Z",
     "shell.execute_reply.started": "2023-07-11T15:51:36.495662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH:\n",
      "the uses of it are different in Hindi.\n",
      "\n",
      "HINDI:\n",
      "इसके उपयोग अलग हैं।.\n"
     ]
    }
   ],
   "source": [
    "txt = x_test[500]\n",
    "txt, result = inference(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T15:54:39.258236Z",
     "iopub.status.busy": "2023-07-11T15:54:39.257834Z",
     "iopub.status.idle": "2023-07-11T15:55:00.053178Z",
     "shell.execute_reply": "2023-07-11T15:55:00.047515Z",
     "shell.execute_reply.started": "2023-07-11T15:54:39.258204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH:\n",
      "Everyone wants to hear their news anchor say, \"Mister Splashy Pants.\n",
      "\n",
      "HINDI:\n",
      "हर समाचार को अपने समाचार अनुसार कहना चाहते हैं, “मिस्टर स्प्लैशी पान्ट्स.\n"
     ]
    }
   ],
   "source": [
    "txt = x_test[1100]\n",
    "txt, result = inference(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
