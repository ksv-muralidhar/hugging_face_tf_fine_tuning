{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-11T07:02:02.673003Z",
     "iopub.status.busy": "2023-07-11T07:02:02.672629Z",
     "iopub.status.idle": "2023-07-11T07:02:02.678900Z",
     "shell.execute_reply": "2023-07-11T07:02:02.678009Z",
     "shell.execute_reply.started": "2023-07-11T07:02:02.672974Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5TokenizerFast, TFAutoModelForSeq2SeqLM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:12:42.662277Z",
     "iopub.status.busy": "2023-07-11T06:12:42.661190Z",
     "iopub.status.idle": "2023-07-11T06:12:42.669868Z",
     "shell.execute_reply": "2023-07-11T06:12:42.668645Z",
     "shell.execute_reply.started": "2023-07-11T06:12:42.662240Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(url: str, n_rows: int):\n",
    "    data = pd.read_csv(url).iloc[:n_rows, :]\n",
    "    data = data.sample(frac=1).copy()\n",
    "    data.columns = [\"input\", \"target\"]\n",
    "    data = data.loc[(~data[\"input\"].isna()) & (~data[\"target\"].isna())].copy()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:12:44.431947Z",
     "iopub.status.busy": "2023-07-11T06:12:44.431190Z",
     "iopub.status.idle": "2023-07-11T06:12:45.011786Z",
     "shell.execute_reply": "2023-07-11T06:12:45.010789Z",
     "shell.execute_reply.started": "2023-07-11T06:12:44.431900Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_data(url=\"data/eng_french.csv\", n_rows=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:12:46.594855Z",
     "iopub.status.busy": "2023-07-11T06:12:46.594487Z",
     "iopub.status.idle": "2023-07-11T06:12:46.611492Z",
     "shell.execute_reply": "2023-07-11T06:12:46.610394Z",
     "shell.execute_reply.started": "2023-07-11T06:12:46.594826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>Is everyone here?</td>\n",
       "      <td>Tout le monde est-il là ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>Give it to me.</td>\n",
       "      <td>Donne-le-moi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26116</th>\n",
       "      <td>They're all normal.</td>\n",
       "      <td>Elles sont toutes normales.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26590</th>\n",
       "      <td>We adopted a child.</td>\n",
       "      <td>Nous avons adopté un enfant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>I know CPR.</td>\n",
       "      <td>Je connais la RCP.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     input                        target\n",
       "15382    Is everyone here?     Tout le monde est-il là ?\n",
       "5072        Give it to me.                 Donne-le-moi.\n",
       "26116  They're all normal.   Elles sont toutes normales.\n",
       "26590  We adopted a child.  Nous avons adopté un enfant.\n",
       "1295           I know CPR.            Je connais la RCP."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:12:52.735772Z",
     "iopub.status.busy": "2023-07-11T06:12:52.735421Z",
     "iopub.status.idle": "2023-07-11T06:12:52.741098Z",
     "shell.execute_reply": "2023-07-11T06:12:52.739683Z",
     "shell.execute_reply.started": "2023-07-11T06:12:52.735744Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame):\n",
    "    data = data.copy()\n",
    "    data[\"input\"] = \"translate English to French: \" + data[\"input\"].map(unidecode).copy()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:12:58.569090Z",
     "iopub.status.busy": "2023-07-11T06:12:58.568720Z",
     "iopub.status.idle": "2023-07-11T06:12:58.630974Z",
     "shell.execute_reply": "2023-07-11T06:12:58.630048Z",
     "shell.execute_reply.started": "2023-07-11T06:12:58.569058Z"
    }
   },
   "outputs": [],
   "source": [
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:00.455816Z",
     "iopub.status.busy": "2023-07-11T06:13:00.454765Z",
     "iopub.status.idle": "2023-07-11T06:13:00.467496Z",
     "shell.execute_reply": "2023-07-11T06:13:00.466586Z",
     "shell.execute_reply.started": "2023-07-11T06:13:00.455775Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame, input_col: str=\"input\", target_col: str=\"target\", test_size: float=0.1):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data[input_col], data[target_col], \n",
    "                                                        random_state=42, test_size=test_size)\n",
    "    \n",
    "    print(f'x_train.shape: {x_train.shape}, x_test.shape: {x_test.shape}, '+\n",
    "          f'y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}')\n",
    "    x_train, x_test, y_train, y_test = x_train.to_list(), x_test.to_list(), y_train.to_list(), y_test.to_list()\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:02.220844Z",
     "iopub.status.busy": "2023-07-11T06:13:02.220461Z",
     "iopub.status.idle": "2023-07-11T06:13:02.252478Z",
     "shell.execute_reply": "2023-07-11T06:13:02.251392Z",
     "shell.execute_reply.started": "2023-07-11T06:13:02.220815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (72000,), x_test.shape: (8000,), y_train.shape: (72000,), y_test.shape: (8000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:04.995034Z",
     "iopub.status.busy": "2023-07-11T06:13:04.994667Z",
     "iopub.status.idle": "2023-07-11T06:13:05.001383Z",
     "shell.execute_reply": "2023-07-11T06:13:05.000489Z",
     "shell.execute_reply.started": "2023-07-11T06:13:04.995004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"translate English to French: That's what worrying me.\",\n",
       " \"C'est ce qui m'inquiète.\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:07.708727Z",
     "iopub.status.busy": "2023-07-11T06:13:07.707997Z",
     "iopub.status.idle": "2023-07-11T06:13:12.269787Z",
     "shell.execute_reply": "2023-07-11T06:13:12.268839Z",
     "shell.execute_reply.started": "2023-07-11T06:13:07.708693Z"
    }
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "CHECKPOINT = \"t5-small\"\n",
    "N_TOKENS = 100 # considering only 100 tokens due to memory constraints\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:12.272376Z",
     "iopub.status.busy": "2023-07-11T06:13:12.272002Z",
     "iopub.status.idle": "2023-07-11T06:13:12.279028Z",
     "shell.execute_reply": "2023-07-11T06:13:12.278037Z",
     "shell.execute_reply.started": "2023-07-11T06:13:12.272342Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(input: list, target: list, n_tokens: int):\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(CHECKPOINT)\n",
    "    print(f'Example:\\n{input[0]}\\n{tokenizer.tokenize(input[0])}')\n",
    "    tokenized_data = tokenizer(text=input, text_target=target, max_length=n_tokens, truncation=True, padding=\"max_length\")\n",
    "    return tokenized_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:12.281121Z",
     "iopub.status.busy": "2023-07-11T06:13:12.280279Z",
     "iopub.status.idle": "2023-07-11T06:13:13.135223Z",
     "shell.execute_reply": "2023-07-11T06:13:13.134226Z",
     "shell.execute_reply.started": "2023-07-11T06:13:12.281088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c378a1466d4316a7f1a921c94070c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9efed7b3cf42b4b00d03e2e5422bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9661f0ac5b2743898008cb863b02ce62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "translate English to French: That's what worrying me.\n",
      "['▁translate', '▁English', '▁to', '▁French', ':', '▁That', \"'\", 's', '▁what', '▁worrying', '▁me', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[13959, 1566, 12, 2379, 10, 466, 31, 7, 125, 19348, 140, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [13959, 1566, 12, 2379, 10, 27, 737, 31, 17, 214, 255, 47, 3, 1092, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[205, 31, 222, 197, 285, 3, 51, 31, 77, 1169, 9831, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1022, 3, 29, 15, 3, 7, 11277, 330, 546, 31, 693, 4104, 29412, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(input=x_train[:2], target=y_train[:2], n_tokens=N_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:15.394875Z",
     "iopub.status.busy": "2023-07-11T06:13:15.394517Z",
     "iopub.status.idle": "2023-07-11T06:13:27.360046Z",
     "shell.execute_reply": "2023-07-11T06:13:27.357894Z",
     "shell.execute_reply.started": "2023-07-11T06:13:15.394846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "translate English to French: That's what worrying me.\n",
      "['▁translate', '▁English', '▁to', '▁French', ':', '▁That', \"'\", 's', '▁what', '▁worrying', '▁me', '.']\n",
      "Example:\n",
      "translate English to French: Don't yell at me.\n",
      "['▁translate', '▁English', '▁to', '▁French', ':', '▁Don', \"'\", 't', '▁', 'y', 'ell', '▁at', '▁me', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = tokenize(input=x_train, target=y_train, n_tokens=N_TOKENS)\n",
    "tokenized_test = tokenize(input=x_test, target=y_test, n_tokens=N_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:27.364565Z",
     "iopub.status.busy": "2023-07-11T06:13:27.364247Z",
     "iopub.status.idle": "2023-07-11T06:13:27.370803Z",
     "shell.execute_reply": "2023-07-11T06:13:27.369666Z",
     "shell.execute_reply.started": "2023-07-11T06:13:27.364539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=100, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:27.373373Z",
     "iopub.status.busy": "2023-07-11T06:13:27.372681Z",
     "iopub.status.idle": "2023-07-11T06:13:27.383775Z",
     "shell.execute_reply": "2023-07-11T06:13:27.382730Z",
     "shell.execute_reply.started": "2023-07-11T06:13:27.373336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=100, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=100, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=100, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=100, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=100, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:27.386523Z",
     "iopub.status.busy": "2023-07-11T06:13:27.386090Z",
     "iopub.status.idle": "2023-07-11T06:13:27.394396Z",
     "shell.execute_reply": "2023-07-11T06:13:27.393371Z",
     "shell.execute_reply.started": "2023-07-11T06:13:27.386483Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_tf_tensors(data):\n",
    "    data = tf.data.Dataset.from_tensor_slices(dict(data))\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:13:30.085366Z",
     "iopub.status.busy": "2023-07-11T06:13:30.084980Z",
     "iopub.status.idle": "2023-07-11T06:14:45.545559Z",
     "shell.execute_reply": "2023-07-11T06:14:45.544382Z",
     "shell.execute_reply.started": "2023-07-11T06:13:30.085309Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tf_data = return_tf_tensors(tokenized_train)\n",
    "test_tf_data = return_tf_tensors(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:14:45.548043Z",
     "iopub.status.busy": "2023-07-11T06:14:45.547590Z",
     "iopub.status.idle": "2023-07-11T06:14:45.696971Z",
     "shell.execute_reply": "2023-07-11T06:14:45.696015Z",
     "shell.execute_reply.started": "2023-07-11T06:14:45.548008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([13959,  1566,    12,  2379,    10,   466,    31,     7,   125,\n",
      "       19348,   140,     5,     1,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'labels': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([ 205,   31,  222,  197,  285,    3,   51,   31,   77, 1169, 9831,\n",
      "          5,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "for i in train_tf_data.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:14:45.699053Z",
     "iopub.status.busy": "2023-07-11T06:14:45.698421Z",
     "iopub.status.idle": "2023-07-11T06:14:45.707580Z",
     "shell.execute_reply": "2023-07-11T06:14:45.706504Z",
     "shell.execute_reply.started": "2023-07-11T06:14:45.699014Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(train_data, val_data, epochs=2, eta=1e-4, early_stopping_patience=1, batch_size=BATCH_SIZE):\n",
    "    with strategy.scope():\n",
    "        model = TFAutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(eta))\n",
    "\n",
    "    print(model.summary())\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=early_stopping_patience, mode=\"min\")\n",
    "    model.fit(train_data.shuffle(len(train_data)).batch(batch_size), validation_data=val_data.shuffle(len(val_data)).batch(batch_size), \n",
    "          epochs=epochs, callbacks=[early_stop])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:14:45.710634Z",
     "iopub.status.busy": "2023-07-11T06:14:45.710115Z",
     "iopub.status.idle": "2023-07-11T06:49:14.296924Z",
     "shell.execute_reply": "2023-07-11T06:49:14.295761Z",
     "shell.execute_reply.started": "2023-07-11T06:14:45.710598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f599e65b71604f04b815f37ddec8514b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c120fba62444988b26e2b8e028f53aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tft5_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shared (Embedding)          multiple                  16449536  \n",
      "                                                                 \n",
      " encoder (TFT5MainLayer)     multiple                  35330816  \n",
      "                                                                 \n",
      " decoder (TFT5MainLayer)     multiple                  41625344  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,506,624\n",
      "Trainable params: 60,506,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "2250/2250 [==============================] - 1073s 439ms/step - loss: 0.1983 - val_loss: 0.0694\n",
      "Epoch 2/2\n",
      "2250/2250 [==============================] - 976s 433ms/step - loss: 0.0799 - val_loss: 0.0617\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(train_data=train_tf_data, val_data=test_tf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:53:43.383232Z",
     "iopub.status.busy": "2023-07-11T06:53:43.382728Z",
     "iopub.status.idle": "2023-07-11T06:53:43.389353Z",
     "shell.execute_reply": "2023-07-11T06:53:43.388475Z",
     "shell.execute_reply.started": "2023-07-11T06:53:43.383186Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_tokenize(input: list, n_tokens: int):\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(CHECKPOINT)\n",
    "    tokenized_data = tokenizer(text=input, max_length=n_tokens, truncation=True, padding=\"max_length\", return_tensors=\"tf\")\n",
    "    return tokenizer, tokenized_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:54:20.542617Z",
     "iopub.status.busy": "2023-07-11T06:54:20.542125Z",
     "iopub.status.idle": "2023-07-11T06:54:20.553653Z",
     "shell.execute_reply": "2023-07-11T06:54:20.552064Z",
     "shell.execute_reply.started": "2023-07-11T06:54:20.542576Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(txt: str):\n",
    "    test_data = [\"translate English to French: \" + txt]\n",
    "    inference_tokenizer, tokenized_data = inference_tokenize(input=test_data, n_tokens=N_TOKENS)\n",
    "    pred = model.generate(**tokenized_data, max_new_tokens=N_TOKENS)\n",
    "    result = inference_tokenizer.decode(pred[0])\n",
    "    result = re.sub(\"<.*?>\", \"\", result).strip()\n",
    "    print(f\"ENGLISH:\\n{txt}\\n\\nFRENCH:\\n{result}\")\n",
    "    return (txt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:54:21.274885Z",
     "iopub.status.busy": "2023-07-11T06:54:21.274182Z",
     "iopub.status.idle": "2023-07-11T06:54:28.445436Z",
     "shell.execute_reply": "2023-07-11T06:54:28.444391Z",
     "shell.execute_reply.started": "2023-07-11T06:54:21.274851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH:\n",
      "\n",
      "Heavy rainfall in several parts of north India has plunged the region into chaos, with more than 28 reported dead in the past three days.\n",
      "\n",
      "\n",
      "FRENCH:\n",
      "Des pluies intenses dans plusieurs parties du nord de l'Inde ont plongé la région dans le chaos, plus de 28 personnes ayant été déclarées mortes au cours des trois derniers jours.\n"
     ]
    }
   ],
   "source": [
    "txt = '''\n",
    "Heavy rainfall in several parts of north India has plunged the region into chaos, with more than 28 reported dead in the past three days.\n",
    "'''\n",
    "txt, result = inference(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T06:56:46.074601Z",
     "iopub.status.busy": "2023-07-11T06:56:46.074209Z",
     "iopub.status.idle": "2023-07-11T06:56:59.940566Z",
     "shell.execute_reply": "2023-07-11T06:56:59.939521Z",
     "shell.execute_reply.started": "2023-07-11T06:56:46.074569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH:\n",
      "\n",
      "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
      "\n",
      "\n",
      "FRENCH:\n",
      "L'apprentissage par machine est une branche de l'intelligence artificielle (AI) et de l'informatique qui se concentre sur l'utilisation de données et d'algorithmes pour imiter la façon dont les humains apprennent, améliorant progressivement sa précision.\n"
     ]
    }
   ],
   "source": [
    "txt = '''\n",
    "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "'''\n",
    "txt, result = inference(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
