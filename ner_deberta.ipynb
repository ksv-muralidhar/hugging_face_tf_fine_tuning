{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf91a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import cloudpickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DebertaTokenizerFast, TFAutoModelForTokenClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928652b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:43.821028Z",
     "iopub.status.busy": "2023-11-15T16:24:43.820467Z",
     "iopub.status.idle": "2023-11-15T16:24:43.829284Z",
     "shell.execute_reply": "2023-11-15T16:24:43.828468Z",
     "shell.execute_reply.started": "2023-11-15T16:24:43.820994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    '''\n",
    "    Label Encoder to encode and decode the entity labels\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.label_mapping = {'O': 0, \n",
    "                             'B-geo': 1, \n",
    "                             'I-geo': 2, \n",
    "                             'B-gpe': 3, \n",
    "                             'I-gpe': 4, \n",
    "                             'B-per': 5,\n",
    "                             'I-per': 6,\n",
    "                             'B-org': 7,\n",
    "                             'I-org': 8,\n",
    "                             'B-tim': 9,\n",
    "                             'I-tim': 10,\n",
    "                             'B-art': 11, \n",
    "                             'I-art': 12,\n",
    "                             'B-nat': 13,\n",
    "                             'I-nat': 14,\n",
    "                             'B-eve': 15,\n",
    "                             'I-eve': 16,\n",
    "                             '[CLS]': -100,\n",
    "                             '[SEP]': -100}\n",
    "        \n",
    "        self.inverse_label_mapping = {}\n",
    "    \n",
    "    def fit(self, x: pd.Series):\n",
    "        self.inverse_label_mapping = {value: key for key, value in self.label_mapping.items()}\n",
    "        return self\n",
    "        \n",
    "    def transform(self, x: pd.Series):\n",
    "        x = x.map(self.label_mapping)\n",
    "        return x\n",
    "    \n",
    "    def inverse_transform(self, x: pd.Series):\n",
    "        x = x.map(self.inverse_label_mapping)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e059506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:43.830774Z",
     "iopub.status.busy": "2023-11-15T16:24:43.830363Z",
     "iopub.status.idle": "2023-11-15T16:24:44.879241Z",
     "shell.execute_reply": "2023-11-15T16:24:44.878444Z",
     "shell.execute_reply.started": "2023-11-15T16:24:43.830721Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting and saving Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "df = pd.read_csv('general_ner_dataset.csv', encoding='unicode_escape')\n",
    "label_encoder.fit(df['Tag'])\n",
    "with open('hf_ner_label_encoder.bin', 'wb') as f:\n",
    "    cloudpickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d29214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:44.881476Z",
     "iopub.status.busy": "2023-11-15T16:24:44.881192Z",
     "iopub.status.idle": "2023-11-15T16:24:44.887181Z",
     "shell.execute_reply": "2023-11-15T16:24:44.886217Z",
     "shell.execute_reply.started": "2023-11-15T16:24:44.881452Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data source: https://www.kaggle.com/datasets/saurabhprajapat/named-entity-recognition\n",
    "def get_preprocessed_data(file_path):\n",
    "    '''\n",
    "    Function to read the data from CSV and collect tokens and tags of each\n",
    "    sentence as lists.\n",
    "    '''\n",
    "    df = pd.read_csv(file_path, encoding='unicode_escape')\n",
    "    df = df.groupby('Sentence #', as_index=False).agg({'Tag': lambda x: list(x), 'Word': lambda x: list(x)})\n",
    "    df.drop(columns='Sentence #', inplace=True)\n",
    "    df.columns = ['target', 'text']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3852e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:44.888466Z",
     "iopub.status.busy": "2023-11-15T16:24:44.888176Z",
     "iopub.status.idle": "2023-11-15T16:24:44.902607Z",
     "shell.execute_reply": "2023-11-15T16:24:44.901784Z",
     "shell.execute_reply.started": "2023-11-15T16:24:44.888421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inputs_adjusted_labels(list_of_texts, list_of_labels, label_encoder, max_token_length=50):\n",
    "    '''\n",
    "    Function to rearrange the entity labels to match with the sub-word tokens and \n",
    "    [CLS], [PAD] and [SEP] tokens\n",
    "    '''\n",
    "    model_checkpoint = \"microsoft/deberta-base\"\n",
    "    tokenizer = DebertaTokenizerFast.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "    \n",
    "    adjusted_labels = []\n",
    "    adjusted_encoded_labels = []\n",
    "    tokenized_inputs = {}\n",
    "    \n",
    "    for idx in range(len(list_of_texts)):\n",
    "        text = list_of_texts[idx]\n",
    "        labels = list_of_labels[idx]\n",
    "        \n",
    "        #####################################\n",
    "        #     Input Tokenization Start      #\n",
    "        #####################################\n",
    "    \n",
    "        inputs = tokenizer(text, is_split_into_words=True, max_length=max_token_length, truncation=True, padding=\"max_length\")\n",
    "        word_ids = inputs.word_ids()\n",
    "        # print(word_ids)\n",
    "        \n",
    "        \n",
    "        if len(tokenized_inputs) == 0:\n",
    "            tokenized_inputs['input_ids'] = [inputs['input_ids']]\n",
    "            tokenized_inputs['attention_mask'] = [inputs['attention_mask']]\n",
    "        else:\n",
    "            tokenized_inputs['input_ids'].append(inputs['input_ids'])\n",
    "            tokenized_inputs['attention_mask'].append(inputs['attention_mask'])\n",
    "        \n",
    "        #####################################\n",
    "        #     Input Tokenization End        #\n",
    "        #####################################\n",
    "        \n",
    "        #####################################\n",
    "        #     Label Rearrangement Start     #\n",
    "        #####################################\n",
    "        res = ['[CLS]']\n",
    "        p = 1\n",
    "        \n",
    "        while p < len(word_ids):\n",
    "            if word_ids[p] is None:\n",
    "                res.append('[SEP]')\n",
    "                p += 1\n",
    "                continue\n",
    "            prev_label = res[p-1]\n",
    "            curr_label = labels[word_ids[p]]\n",
    "            if prev_label.find('-') != -1:\n",
    "                prev_label_split = prev_label.split(\"-\")\n",
    "            else:\n",
    "                prev_label_split = ['PO', 'PO']\n",
    "            prev_label_prefix, prev_label_suffix = prev_label_split\n",
    "\n",
    "\n",
    "            if curr_label.find('-') != -1:\n",
    "                curr_label_split = curr_label.split(\"-\")\n",
    "            else:\n",
    "                curr_label_split = ['CO', 'CO']\n",
    "            curr_label_prefix, curr_label_suffix = curr_label_split\n",
    "\n",
    "            if ((prev_label_prefix == 'B') or (prev_label_prefix == 'I')) and (prev_label_suffix == curr_label_suffix):\n",
    "                res.append('I-'+prev_label_suffix)\n",
    "            else:\n",
    "                res.append(curr_label)\n",
    "            p += 1\n",
    "            \n",
    "        #####################################\n",
    "        #     Label Rearrangement End       #\n",
    "        #####################################\n",
    "        \n",
    "        adjusted_labels.append(res)\n",
    "        adjusted_encoded_labels.append([*label_encoder.transform(pd.Series(res))])\n",
    "    return tokenized_inputs, adjusted_labels, adjusted_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dadbacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:44.903793Z",
     "iopub.status.busy": "2023-11-15T16:24:44.903519Z",
     "iopub.status.idle": "2023-11-15T16:24:44.918945Z",
     "shell.execute_reply": "2023-11-15T16:24:44.918060Z",
     "shell.execute_reply.started": "2023-11-15T16:24:44.903766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_processed_train_test(file_path='general_ner_dataset.csv', label_encoder_path='hf_ner_label_encoder.bin',\n",
    "                             test_size: float=0.15, input_col: str='text', target_col: str='target', \n",
    "                             max_token_length=50, random_state=42):\n",
    "    \n",
    "    '''\n",
    "    Function to read CSV data and return preprocessed train and test sets\n",
    "    '''\n",
    "    df = get_preprocessed_data(file_path)\n",
    "    x = df[input_col].copy()\n",
    "    y = df[target_col].copy()\n",
    "    del(df)\n",
    "    \n",
    "    if test_size > 0:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "    else:\n",
    "        x_train, y_train = x, y\n",
    "        x_test, y_test = None, None\n",
    "    \n",
    "    x_train, y_train  = x_train.to_list(), y_train.to_list()\n",
    "    if x_test is not None:\n",
    "        x_test, y_test = x_test.to_list(), y_test.to_list()\n",
    "    \n",
    "    with open(label_encoder_path, 'rb') as f:\n",
    "        label_encoder = cloudpickle.load(f)\n",
    "    \n",
    "    x_train, _, y_train = get_inputs_adjusted_labels(x_train, y_train, label_encoder, max_token_length)\n",
    "    \n",
    "    train = x_train\n",
    "    train['labels'] = y_train\n",
    "    \n",
    "    if x_test is not None:\n",
    "        x_test, _, y_test = get_inputs_adjusted_labels(x_test, y_test, label_encoder, max_token_length)\n",
    "        test = x_test\n",
    "        test['labels'] = y_test\n",
    "    else:\n",
    "        test = None\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8849e802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:44.920358Z",
     "iopub.status.busy": "2023-11-15T16:24:44.920092Z",
     "iopub.status.idle": "2023-11-15T16:24:44.933484Z",
     "shell.execute_reply": "2023-11-15T16:24:44.932659Z",
     "shell.execute_reply.started": "2023-11-15T16:24:44.920335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_tokens_labels(idx):\n",
    "    '''\n",
    "    Function to visualize tokens and entity labels\n",
    "    before and after preprocessing\n",
    "    '''\n",
    "    df = get_preprocessed_data('general_ner_dataset.csv')\n",
    "    tokens = df.iloc[idx, 1]\n",
    "    labels = df.iloc[idx, 0]\n",
    "    print('BEFORE PREPROCESSING')\n",
    "    for tok, lab in zip(tokens, labels):\n",
    "        print(f'{tok: <20}{lab}')\n",
    "    \n",
    "    \n",
    "    x, _ = get_processed_train_test(max_token_length=50, test_size=0.0)\n",
    "    input_ids = x['input_ids'][idx]\n",
    "    labels = x['labels'][idx]\n",
    "    model_checkpoint = \"microsoft/deberta-base\"\n",
    "    tokenizer = DebertaTokenizerFast.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(x['input_ids'][idx])\n",
    "\n",
    "    label_encoder_path='hf_ner_label_encoder.bin'\n",
    "    with open(label_encoder_path, 'rb') as f:\n",
    "        label_encoder = cloudpickle.load(f)\n",
    "    \n",
    "    print('\\nAFTER PREPROCESSING')\n",
    "    labels = [*label_encoder.inverse_transform(pd.Series(labels))]\n",
    "    for tok, lab in zip(tokens, labels):\n",
    "        print(f'{tok: <20}{lab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85cb0608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:24:44.934644Z",
     "iopub.status.busy": "2023-11-15T16:24:44.934392Z",
     "iopub.status.idle": "2023-11-15T16:25:37.152679Z",
     "shell.execute_reply": "2023-11-15T16:25:37.151795Z",
     "shell.execute_reply.started": "2023-11-15T16:24:44.934601Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE PREPROCESSING\n",
      "Spain               B-gpe\n",
      "has                 O\n",
      "begun               O\n",
      "a                   O\n",
      "trial               O\n",
      "for                 O\n",
      "24                  O\n",
      "suspected           O\n",
      "al-Qaida            B-org\n",
      "members             O\n",
      ",                   O\n",
      "including           O\n",
      "three               O\n",
      "accused             O\n",
      "of                  O\n",
      "helping             O\n",
      "plan                O\n",
      "the                 O\n",
      "September           B-tim\n",
      "11                  I-tim\n",
      ",                   I-tim\n",
      "2001                I-tim\n",
      "terrorist           O\n",
      "attacks             O\n",
      "in                  O\n",
      "the                 O\n",
      "United              B-geo\n",
      "States              I-geo\n",
      ".                   O\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4f41012243426c82979474ec0a1619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54f28bed0ce4f2e81ce8d7024bccadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099a1b3c7bfc4943bf7d30c7cc5184c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd35ba0828d14105a6a6f66c0bb9ec81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER PREPROCESSING\n",
      "[CLS]               [SEP]\n",
      "ĠSpain              B-gpe\n",
      "Ġhas                O\n",
      "Ġbegun              O\n",
      "Ġa                  O\n",
      "Ġtrial              O\n",
      "Ġfor                O\n",
      "Ġ24                 O\n",
      "Ġsuspected          O\n",
      "Ġal                 B-org\n",
      "-                   I-org\n",
      "Qaida               I-org\n",
      "Ġmembers            O\n",
      "Ġ,                  O\n",
      "Ġincluding          O\n",
      "Ġthree              O\n",
      "Ġaccused            O\n",
      "Ġof                 O\n",
      "Ġhelping            O\n",
      "Ġplan               O\n",
      "Ġthe                O\n",
      "ĠSeptember          B-tim\n",
      "Ġ11                 I-tim\n",
      "Ġ,                  I-tim\n",
      "Ġ2001               I-tim\n",
      "Ġterrorist          O\n",
      "Ġattacks            O\n",
      "Ġin                 O\n",
      "Ġthe                O\n",
      "ĠUnited             B-geo\n",
      "ĠStates             I-geo\n",
      "Ġ.                  O\n",
      "[SEP]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n",
      "[PAD]               [SEP]\n"
     ]
    }
   ],
   "source": [
    "visualize_tokens_labels(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b4a5297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:25:37.154679Z",
     "iopub.status.busy": "2023-11-15T16:25:37.154232Z",
     "iopub.status.idle": "2023-11-15T16:25:37.159959Z",
     "shell.execute_reply": "2023-11-15T16:25:37.159050Z",
     "shell.execute_reply.started": "2023-11-15T16:25:37.154645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_tf_tensors(data):\n",
    "    data = tf.data.Dataset.from_tensor_slices(dict(data))\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493c0193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:25:37.164980Z",
     "iopub.status.busy": "2023-11-15T16:25:37.164641Z",
     "iopub.status.idle": "2023-11-15T16:25:37.173125Z",
     "shell.execute_reply": "2023-11-15T16:25:37.172241Z",
     "shell.execute_reply.started": "2023-11-15T16:25:37.164949Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHECKPOINT = \"microsoft/deberta-base\"\n",
    "N_TOKENS = 50\n",
    "BATCH_SIZE = 32\n",
    "N_LABELS = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea90b523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:25:37.174583Z",
     "iopub.status.busy": "2023-11-15T16:25:37.174320Z",
     "iopub.status.idle": "2023-11-15T16:26:24.871801Z",
     "shell.execute_reply": "2023-11-15T16:26:24.871010Z",
     "shell.execute_reply.started": "2023-11-15T16:25:37.174560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = get_processed_train_test(file_path='general_ner_dataset.csv', max_token_length=N_TOKENS, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1a89652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:26:24.873683Z",
     "iopub.status.busy": "2023-11-15T16:26:24.873322Z",
     "iopub.status.idle": "2023-11-15T16:26:51.294236Z",
     "shell.execute_reply": "2023-11-15T16:26:51.293132Z",
     "shell.execute_reply.started": "2023-11-15T16:26:24.873648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tf_data = return_tf_tensors(train)\n",
    "test_tf_data = return_tf_tensors(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8535f6b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:26:51.295890Z",
     "iopub.status.busy": "2023-11-15T16:26:51.295514Z",
     "iopub.status.idle": "2023-11-15T16:26:51.357782Z",
     "shell.execute_reply": "2023-11-15T16:26:51.356927Z",
     "shell.execute_reply.started": "2023-11-15T16:26:51.295858Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([    1,    20,  5442,   443,    21,  7225,     7,  1221,    11,\n",
      "       43289,  2156,    61,  9533,     5,  3285,  4745,   148,   623,\n",
      "        1771,    38,     8,  1143,     7, 26094,     5,  2771,   911,\n",
      "         454,  5201,    11, 14873,   479,     2,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32)>, 'labels': <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([-100,    0,    0,    0,    0,    0,    0,    1,    0,    9,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,   15,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    9,    0, -100,\n",
      "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "       -100, -100, -100, -100, -100, -100], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "for i in train_tf_data.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60bb3ad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:26:51.359808Z",
     "iopub.status.busy": "2023-11-15T16:26:51.359183Z",
     "iopub.status.idle": "2023-11-15T16:26:51.366943Z",
     "shell.execute_reply": "2023-11-15T16:26:51.366089Z",
     "shell.execute_reply.started": "2023-11-15T16:26:51.359772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_model(train_data, val_data, epochs=2, eta=1e-4, early_stopping_patience=1, batch_size=BATCH_SIZE):\n",
    "    model = TFAutoModelForTokenClassification.from_pretrained(CHECKPOINT, \n",
    "                                                              num_labels=N_LABELS, \n",
    "                                                              attention_probs_dropout_prob=0.4,\n",
    "                                                              hidden_dropout_prob=0.4)\n",
    "    learning_schedule = PolynomialDecay(initial_learning_rate=eta, decay_steps=len(train_data) * epochs, end_learning_rate=0)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_schedule))\n",
    "\n",
    "    print(model.summary())\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=early_stopping_patience, mode=\"min\")\n",
    "    model.fit(train_data.shuffle(len(train_data)).batch(batch_size), validation_data=val_data.shuffle(len(val_data)).batch(batch_size), \n",
    "          epochs=epochs, callbacks=[early_stop])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6933ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:26:51.368452Z",
     "iopub.status.busy": "2023-11-15T16:26:51.368135Z",
     "iopub.status.idle": "2023-11-15T16:56:24.260260Z",
     "shell.execute_reply": "2023-11-15T16:56:24.259449Z",
     "shell.execute_reply.started": "2023-11-15T16:26:51.368421Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad8637ae45d43aabd86bf42df416819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/555M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaForTokenClassification.\n",
      "\n",
      "Some layers of TFDebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['dropout', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_deberta_for_token_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " deberta (TFDebertaMainLaye  multiple                  138601728 \n",
      " r)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  13842     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138615570 (528.78 MB)\n",
      "Trainable params: 138615570 (528.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "1274/1274 [==============================] - 521s 353ms/step - loss: 0.2604 - val_loss: 0.1856\n",
      "Epoch 2/15\n",
      "1274/1274 [==============================] - 417s 327ms/step - loss: 0.2096 - val_loss: 0.1745\n",
      "Epoch 3/15\n",
      "1274/1274 [==============================] - 415s 325ms/step - loss: 0.1667 - val_loss: 0.1789\n",
      "Epoch 4/15\n",
      "1274/1274 [==============================] - 414s 325ms/step - loss: 0.1454 - val_loss: 0.1861\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(train_data=train_tf_data, val_data=test_tf_data, epochs=15, early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00330fef",
   "metadata": {},
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4de67d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:38.540854Z",
     "iopub.status.busy": "2023-11-15T16:56:38.540026Z",
     "iopub.status.idle": "2023-11-15T16:56:38.545533Z",
     "shell.execute_reply": "2023-11-15T16:56:38.544761Z",
     "shell.execute_reply.started": "2023-11-15T16:56:38.540819Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return tf.exp(x) / tf.math.reduce_sum(tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfd0ef46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:42.122201Z",
     "iopub.status.busy": "2023-11-15T16:56:42.121857Z",
     "iopub.status.idle": "2023-11-15T16:56:42.136145Z",
     "shell.execute_reply": "2023-11-15T16:56:42.135309Z",
     "shell.execute_reply.started": "2023-11-15T16:56:42.122176Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_output(res):\n",
    "    '''\n",
    "    Function to concatenate sub-word tokens, labels and \n",
    "    compute mean prediction probability of tokens\n",
    "    '''\n",
    "    d = {}\n",
    "    result = []\n",
    "    pred_prob = []\n",
    "    res.append(['-', 'B-b', 0])\n",
    "    for n, i in enumerate(res):\n",
    "        try:\n",
    "            split = i[1].split('-')\n",
    "            token = i[0]\n",
    "            token_prob = i[2]\n",
    "            prefix, suffix = split\n",
    "            if prefix == 'B':\n",
    "                if len(d) != 0:\n",
    "                    result.append([(token.replace(\"Ġ\", \" \").strip(), label, np.mean(pred_prob)) for label, token in d.items()][0])\n",
    "                d = {}\n",
    "                pred_prob = []\n",
    "                pred_prob.append(token_prob)\n",
    "                d[suffix] = token\n",
    "\n",
    "            else:\n",
    "                d[suffix] = d[suffix] + token\n",
    "                pred_prob.append(token_prob)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def inference(txt):\n",
    "    '''\n",
    "    Function that returns model prediction and prediction probabitliy\n",
    "    '''\n",
    "    test_data = [txt]\n",
    "    tokenizer = DebertaTokenizerFast.from_pretrained(CHECKPOINT, add_prefix_space=True)\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    tokenized_data = tokenizer(test_data, is_split_into_words=True, max_length=N_TOKENS, \n",
    "                               truncation=True, padding=\"max_length\")\n",
    "\n",
    "    token_idx_to_consider = tokenized_data.word_ids()\n",
    "    token_idx_to_consider = [i for i in range(len(token_idx_to_consider)) if token_idx_to_consider[i] is not None] \n",
    "\n",
    "    input_ = [tokenized_data['input_ids'], tokenized_data['attention_mask']]\n",
    "    pred_logits = model.predict(input_, verbose=0).logits[0]\n",
    "\n",
    "    pred_prob = tf.map_fn(softmax, pred_logits)\n",
    "\n",
    "    pred_idx = tf.argmax(pred_prob, axis=-1).numpy()\n",
    "    pred_idx = pred_idx[token_idx_to_consider]\n",
    "\n",
    "    pred_prob = tf.math.reduce_max(pred_prob, axis=-1).numpy()\n",
    "    pred_prob = np.round(pred_prob[token_idx_to_consider], 3)\n",
    "    pred_labels = label_encoder.inverse_transform(pd.Series(pred_idx))\n",
    "\n",
    "    result = [[token, label, prob] for token, label, \n",
    "              prob in zip(tokens, pred_labels, pred_prob) if label.find('-') >= 0]\n",
    "    output = process_output(result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0996ccdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:24.286490Z",
     "iopub.status.busy": "2023-11-15T16:56:24.286207Z",
     "iopub.status.idle": "2023-11-15T16:56:32.463337Z",
     "shell.execute_reply": "2023-11-15T16:56:32.462371Z",
     "shell.execute_reply.started": "2023-11-15T16:56:24.286466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Xi Jinping', 'per', 0.996), ('US', 'geo', 0.995), ('Chinese', 'gpe', 0.915)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Xi Jinping arrives in US as his Chinese Dream sputters'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f3612b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:32.465211Z",
     "iopub.status.busy": "2023-11-15T16:56:32.464914Z",
     "iopub.status.idle": "2023-11-15T16:56:32.922280Z",
     "shell.execute_reply": "2023-11-15T16:56:32.921374Z",
     "shell.execute_reply.started": "2023-11-15T16:56:32.465186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sri Lanka', 'geo', 0.7195), ('Gotabaya Rajapaksa', 'per', 0.71828574), ('Mahinda Ċ', 'per', 0.98825)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Sri Lanka's top court has ruled that ex-president Gotabaya Rajapaksa and his brother Mahinda \n",
    "were among 13 former leaders responsible for the country's worst-ever financial crisis.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b084d7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:32.925846Z",
     "iopub.status.busy": "2023-11-15T16:56:32.925072Z",
     "iopub.status.idle": "2023-11-15T16:56:33.377590Z",
     "shell.execute_reply": "2023-11-15T16:56:33.376693Z",
     "shell.execute_reply.started": "2023-11-15T16:56:32.925815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ukrainian', 'gpe', 0.999), ('President Volodymyr Zelensky', 'per', 0.998), ('Andriy Yermak', 'per', 0.9725), ('Ukrainian', 'gpe', 0.9986667), ('Dnipro', 'geo', 0.98125)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Ukrainian President Volodymyr Zelensky's chief of staff Andriy Yermak has said that \n",
    "Ukrainian forces have gained a foothold on the left (eastern) bank of the Dnipro river'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77400f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:57:25.613420Z",
     "iopub.status.busy": "2023-11-15T16:57:25.612947Z",
     "iopub.status.idle": "2023-11-15T16:57:26.101325Z",
     "shell.execute_reply": "2023-11-15T16:57:26.100465Z",
     "shell.execute_reply.started": "2023-11-15T16:57:25.613383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ar', 'org', 0.35), ('Ogba', 'geo', 0.99399996), ('Lagos', 'geo', 0.97650003), ('Nigerian', 'gpe', 0.999)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Arinola Omolayo owns a frozen food store in Ogba, a suburb of Lagos, Nigerian commercial nerve centre, \n",
    "where she sells mostly imported chicken, fish and turkey.'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1654d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:33.837251Z",
     "iopub.status.busy": "2023-11-15T16:56:33.836961Z",
     "iopub.status.idle": "2023-11-15T16:56:34.279510Z",
     "shell.execute_reply": "2023-11-15T16:56:34.278603Z",
     "shell.execute_reply.started": "2023-11-15T16:56:33.837225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Courteney Cox', 'per', 0.98675007), ('Matt Le Blanc', 'per', 0.9906666), ('Mathew Perry', 'per', 0.98233336)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Friends stars Courteney Cox and Matt Le Blanc have both paid their first \n",
    "individual tributes to co-star Mathew Perry, following his death last month.'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "811d54f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:58:07.509615Z",
     "iopub.status.busy": "2023-11-15T16:58:07.509223Z",
     "iopub.status.idle": "2023-11-15T16:58:07.956637Z",
     "shell.execute_reply": "2023-11-15T16:58:07.955749Z",
     "shell.execute_reply.started": "2023-11-15T16:58:07.509586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Haris Rauf', 'per', 0.97959995), ('Cricket World', 'org', 0.606), ('Cup', 'eve', 0.382)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Haris Rauf breaks record for conceding most runs in history of Cricket World Cup.'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a59cb815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:34.809742Z",
     "iopub.status.busy": "2023-11-15T16:56:34.808868Z",
     "iopub.status.idle": "2023-11-15T16:56:35.271858Z",
     "shell.execute_reply": "2023-11-15T16:56:35.270938Z",
     "shell.execute_reply.started": "2023-11-15T16:56:34.809696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alistair Macrow', 'per', 0.9342), ('since July', 'tim', 0.923), ('BBC', 'org', 0.997)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Alistair Macrow told MPs it had received more than 400 \n",
    "complaints from workers since July, when the BBC uncovered hundreds of allegations.'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc517ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:35.274302Z",
     "iopub.status.busy": "2023-11-15T16:56:35.273878Z",
     "iopub.status.idle": "2023-11-15T16:56:35.732830Z",
     "shell.execute_reply": "2023-11-15T16:56:35.731948Z",
     "shell.execute_reply.started": "2023-11-15T16:56:35.274269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Google', 'org', 0.992), ('Lendlease', 'org', 0.921), ('Bay Area', 'geo', 0.99399996)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Google, Lendlease axe plans for $15 billion development in Bay Area'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9b75cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:35.735224Z",
     "iopub.status.busy": "2023-11-15T16:56:35.734927Z",
     "iopub.status.idle": "2023-11-15T16:56:36.182597Z",
     "shell.execute_reply": "2023-11-15T16:56:36.181662Z",
     "shell.execute_reply.started": "2023-11-15T16:56:35.735198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sir Richard Branson', 'per', 0.996), ('BBC', 'org', 0.995), ('Virgin Group', 'org', 0.996)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Sir Richard Branson has told the BBC that he has never faced media coverage as \"painful\" \n",
    "as when he attempted to acquire a loan for his Virgin Group during the pandemic.'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e54d1060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:36.184643Z",
     "iopub.status.busy": "2023-11-15T16:56:36.184377Z",
     "iopub.status.idle": "2023-11-15T16:56:36.640458Z",
     "shell.execute_reply": "2023-11-15T16:56:36.639491Z",
     "shell.execute_reply.started": "2023-11-15T16:56:36.184619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Carlos Alcaraz', 'per', 0.9885), ('ATP', 'org', 0.784), ('Andrey Rublev', 'per', 0.9375), ('Russian', 'gpe', 0.999)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Carlos Alcaraz kept alive his semi-final hopes in his maiden ATP Finals campaign with a win \n",
    "over Andrey Rublev in which the Russian hit himself so hard with his racquet he drew blood.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f6383c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:36.645634Z",
     "iopub.status.busy": "2023-11-15T16:56:36.645371Z",
     "iopub.status.idle": "2023-11-15T16:56:37.112318Z",
     "shell.execute_reply": "2023-11-15T16:56:37.111352Z",
     "shell.execute_reply.started": "2023-11-15T16:56:36.645611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rishi Sunak', 'per', 0.99050003), ('Rwanda', 'geo', 0.948)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Rishi Sunak says the government is working on a new treaty with Rwanda, after \n",
    "the government's asylum seeker plan was ruled unlawful\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4423ccc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:37.114308Z",
     "iopub.status.busy": "2023-11-15T16:56:37.114005Z",
     "iopub.status.idle": "2023-11-15T16:56:37.612950Z",
     "shell.execute_reply": "2023-11-15T16:56:37.611960Z",
     "shell.execute_reply.started": "2023-11-15T16:56:37.114285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "txt = '''How many people cross the sea in small boats and how many claim asylum\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fb26dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:37.615232Z",
     "iopub.status.busy": "2023-11-15T16:56:37.614935Z",
     "iopub.status.idle": "2023-11-15T16:56:38.088688Z",
     "shell.execute_reply": "2023-11-15T16:56:38.087620Z",
     "shell.execute_reply.started": "2023-11-15T16:56:37.615207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "txt = '''In a blistering letter, she said he had \n",
    "repeatedly failed on key policies and broken pledges over immigration.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc3d070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:56:38.093592Z",
     "iopub.status.busy": "2023-11-15T16:56:38.093271Z",
     "iopub.status.idle": "2023-11-15T16:56:38.538119Z",
     "shell.execute_reply": "2023-11-15T16:56:38.537208Z",
     "shell.execute_reply.started": "2023-11-15T16:56:38.093564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Prince William', 'per', 0.981), ('decade', 'tim', 0.84), ('Tuesday', 'tim', 0.995)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Prince William said he believed this was the decade for collective action to protect the planet. \n",
    "He announced the winners of the £1m ($1.2m) prize at a ceremony on Tuesday.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41766d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T16:59:40.483961Z",
     "iopub.status.busy": "2023-11-15T16:59:40.483191Z",
     "iopub.status.idle": "2023-11-15T16:59:40.945638Z",
     "shell.execute_reply": "2023-11-15T16:59:40.944774Z",
     "shell.execute_reply.started": "2023-11-15T16:59:40.483925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Shell', 'org', 0.961), ('Greenpeace', 'org', 0.983)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Shell is suing Greenpeace for $2.1m (£1.7m) in damages after environmental protesters occupied a \n",
    "vessel transporting one of the oil company's floating platforms earlier this year.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee7ff1a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:02:13.538300Z",
     "iopub.status.busy": "2023-11-15T17:02:13.537573Z",
     "iopub.status.idle": "2023-11-15T17:02:14.119105Z",
     "shell.execute_reply": "2023-11-15T17:02:14.118149Z",
     "shell.execute_reply.started": "2023-11-15T17:02:13.538268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gaza', 'geo', 0.995), ('Vivian Silver', 'per', 0.98066664), ('Israel', 'geo', 0.991), ('Gaza', 'geo', 0.99), (\"kibbutz Be'eri\", 'geo', 0.99200004), ('Hamas', 'org', 0.996), ('7 October', 'tim', 0.9845)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''An Israeli-Canadian peace advocate, taken hostage in Gaza, has been killed. Vivian Silver, 74, lived \n",
    "close to Israel's border with Gaza in kibbutz Be'eri - attacked by Hamas during 7 October attacks.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad9c4d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:03:38.334457Z",
     "iopub.status.busy": "2023-11-15T17:03:38.334082Z",
     "iopub.status.idle": "2023-11-15T17:03:38.849016Z",
     "shell.execute_reply": "2023-11-15T17:03:38.848117Z",
     "shell.execute_reply.started": "2023-11-15T17:03:38.334429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Delhi', 'geo', 0.574), ('Indian', 'gpe', 0.999), ('Delhi', 'geo', 0.968), ('Beijing', 'geo', 0.989)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Delhi AQI: Why the Indian capital, Delhi lags behind Beijing in the battle to breathe.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c01f6c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:04:25.902762Z",
     "iopub.status.busy": "2023-11-15T17:04:25.901881Z",
     "iopub.status.idle": "2023-11-15T17:04:26.356910Z",
     "shell.execute_reply": "2023-11-15T17:04:26.356021Z",
     "shell.execute_reply.started": "2023-11-15T17:04:25.902709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('day 4', 'tim', 0.9605), ('Salman Khan', 'per', 0.995), ('India', 'geo', 0.996), ('Wednesday', 'tim', 0.994)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Tiger 3 box office collection day 4: Salman Khan film crosses ₹160 cr in India, likely \n",
    "to earn over ₹20 cr on Wednesday\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a58393c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:05:07.082632Z",
     "iopub.status.busy": "2023-11-15T17:05:07.081713Z",
     "iopub.status.idle": "2023-11-15T17:05:07.559451Z",
     "shell.execute_reply": "2023-11-15T17:05:07.558406Z",
     "shell.execute_reply.started": "2023-11-15T17:05:07.082599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Atlee', 'per', 0.845), ('Shah Rukh Khan', 'per', 0.99275), ('Thalapathy Vijay', 'per', 0.8181667)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Atlee confirms his next film will feature Shah Rukh Khan and Thalapathy Vijay together: Both \n",
    "superstars are ready for it\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac7f92f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:05:50.876891Z",
     "iopub.status.busy": "2023-11-15T17:05:50.876480Z",
     "iopub.status.idle": "2023-11-15T17:05:51.361485Z",
     "shell.execute_reply": "2023-11-15T17:05:51.360578Z",
     "shell.execute_reply.started": "2023-11-15T17:05:50.876859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mohammed Shami', 'per', 0.987), ('ODI Cup', 'org', 0.68733335)]\n"
     ]
    }
   ],
   "source": [
    "txt = '''Mohammed Shami becomes fastest to 50 wickets in ODI World Cup history.\n",
    "'''\n",
    "print(inference(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91456d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
